{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c808ff-fcf3-4ed1-88ca-485689d57168",
   "metadata": {},
   "source": [
    "### Requirements and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba79b7-ef63-4e9d-91ee-53a3051a6a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install textblob\n",
    "!pip install scikit-learn\n",
    "!pip install IPython\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install xgboost\n",
    "!pip install torch\n",
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdffdf5b-4d57-411d-830a-be233d58a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from threading import Thread\n",
    "from xgboost import XGBClassifier\n",
    "import GPUtil\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932b0b9d-bb84-4208-8536-df499eb915ce",
   "metadata": {},
   "source": [
    "### Data loader and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "822e2d67-c6e7-4c73-8498-a75ae90718cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review  rating  \\\n",
      "11368  great hotel just returned hotel stayed 24.08 3...       4   \n",
      "2605   not worth price stayed whirlpool suite 269 nig...       3   \n",
      "4518   great location clean rooms reviewers hotel gre...       4   \n",
      "10638  service service, arrived renaissance friday ex...       2   \n",
      "1962   Title: A Comfortable yet Imperfect Overnight D...       2   \n",
      "\n",
      "                                          cleaned_review  \n",
      "11368  great returned originally petite double tight ...  \n",
      "2605   not worth price whirlpool suite nice worth pri...  \n",
      "4518   great location clean reviewers great bargain l...  \n",
      "10638  service service arrived renaissance friday exp...  \n",
      "1962   title comfortable yet imperfect overnight rece...  \n",
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/cleaned_dataset_processed_balanced.csv').sample(n=1000, random_state=42)\n",
    "print(dataset.head(5))\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d88e2fe-ed00-4143-80b1-50aacdade928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_stratified(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data ensuring proportional representation of all classes\n",
    "    \"\"\"\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Get indices for train and test splits\n",
    "    for train_idx, test_idx in sss.split(X, y):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "    \n",
    "    print(\"Class distribution in splits:\")\n",
    "    print(\"\\nTraining set:\")\n",
    "    print(y_train.value_counts().sort_index())\n",
    "    print(\"\\nTest set:\")\n",
    "    print(y_test.value_counts().sort_index())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdee6bcd-c9cf-40a2-9f41-40b4166f04d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in splits:\n",
      "\n",
      "Training set:\n",
      "rating\n",
      "1    101\n",
      "2    136\n",
      "3     97\n",
      "4    188\n",
      "5    278\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set:\n",
      "rating\n",
      "1    25\n",
      "2    34\n",
      "3    24\n",
      "4    47\n",
      "5    70\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = dataset['cleaned_review']\n",
    "y = dataset['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data_stratified(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab90d19-4f00-4420-8e89-690ac6c2965a",
   "metadata": {},
   "source": [
    "## XGBoost regression training and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487f4953-0713-4301-897b-cd904d41bab0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Plot Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "958d2cb3-d625-47d1-8b4c-53f396d2dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison(results):\n",
    "    \"\"\"Plot comparison of model performances\"\"\"\n",
    "    try:\n",
    "        # Prepare data\n",
    "        models = list(results.keys())\n",
    "        train_scores = [results[m]['train_score'] for m in models]\n",
    "        test_scores = [results[m]['test_score'] for m in models]\n",
    "\n",
    "        # Create plot\n",
    "        x = np.arange(len(models))\n",
    "        width = 0.35\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        rects1 = ax.bar(x - width/2, train_scores, width, label='Train')\n",
    "        rects2 = ax.bar(x + width/2, test_scores, width, label='Test')\n",
    "\n",
    "        # Customize plot\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.set_title('Model Performance Comparison')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(models, rotation=45)\n",
    "        ax.legend()\n",
    "\n",
    "        # Add value labels\n",
    "        def autolabel(rects):\n",
    "            for rect in rects:\n",
    "                height = rect.get_height()\n",
    "                ax.annotate(f'{height:.3f}',\n",
    "                          xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                          xytext=(0, 3),\n",
    "                          textcoords=\"offset points\",\n",
    "                          ha='center', va='bottom')\n",
    "\n",
    "        autolabel(rects1)\n",
    "        autolabel(rects2)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in model comparison plot: {str(e)}\")\n",
    "\n",
    "def plot_top_features_by_class(model, model_name, n_features=10):\n",
    "    \"\"\"\n",
    "    Plot top features for each class separately (for models that support it)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vectorizer = model.named_steps['vectorizer']\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        if model_name in ['Logistic Regression', 'SVM']:\n",
    "            coefficients = model.named_steps['classifier'].coef_\n",
    "            n_classes = coefficients.shape[0]\n",
    "            \n",
    "            # Create subplot grid\n",
    "            n_cols = 2\n",
    "            n_rows = (n_classes + 1) // 2\n",
    "            fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "            axes = axes.ravel()\n",
    "            \n",
    "            for i in range(n_classes):\n",
    "                # Get top features for this class\n",
    "                class_coef = coefficients[i]\n",
    "                top_positive_idx = np.argsort(class_coef)[-n_features:]\n",
    "                top_negative_idx = np.argsort(class_coef)[:n_features]\n",
    "                \n",
    "                # Plot\n",
    "                ax = axes[i]\n",
    "                y_pos = np.arange(n_features * 2)\n",
    "                \n",
    "                # Combine positive and negative features\n",
    "                features = np.concatenate([\n",
    "                    feature_names[top_negative_idx],\n",
    "                    feature_names[top_positive_idx]\n",
    "                ])\n",
    "                importances = np.concatenate([\n",
    "                    class_coef[top_negative_idx],\n",
    "                    class_coef[top_positive_idx]\n",
    "                ])\n",
    "                \n",
    "                ax.barh(y_pos, importances)\n",
    "                ax.set_yticks(y_pos)\n",
    "                ax.set_yticklabels(features)\n",
    "                ax.set_title(f'Class {i+1} Important Features')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Could not plot class-specific features for {model_name}: {str(e)}\")\n",
    "\n",
    "def plot_top_features(model, model_name, n_features=20):\n",
    "    \"\"\"\n",
    "    Plot top n_features for each model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get vectorizer and feature names\n",
    "        vectorizer = model.named_steps['vectorizer']\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Get feature importance based on model type\n",
    "        if model_name in ['Random Forest', 'XGBoost']:\n",
    "            # Tree-based models\n",
    "            importances = model.named_steps['classifier'].feature_importances_\n",
    "            importance_type = 'Feature Importance'\n",
    "        \n",
    "        elif model_name == 'Logistic Regression':\n",
    "            # Get absolute values of coefficients (average across classes for multiclass)\n",
    "            importances = np.abs(model.named_steps['classifier'].coef_).mean(axis=0)\n",
    "            importance_type = 'Coefficient Magnitude'\n",
    "        \n",
    "        elif model_name == 'SVM':\n",
    "            # For LinearSVC, get coefficients from the underlying estimator\n",
    "            importances = np.abs(model.named_steps['classifier'].estimator.coef_).mean(axis=0)\n",
    "            importance_type = 'Coefficient Magnitude'\n",
    "        \n",
    "        elif model_name == 'Naive Bayes':\n",
    "            # For Naive Bayes, use feature log probabilities\n",
    "            importances = np.exp(model.named_steps['classifier'].feature_log_prob_).mean(axis=0)\n",
    "            importance_type = 'Feature Probability'\n",
    "        \n",
    "        # Get top n features\n",
    "        top_indices = np.argsort(importances)[-n_features:]\n",
    "        top_features = feature_names[top_indices]\n",
    "        top_importances = importances[top_indices]\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.barh(range(n_features), top_importances[::-1])\n",
    "        plt.yticks(range(n_features), top_features[::-1])\n",
    "        plt.xlabel(importance_type)\n",
    "        plt.title(f'Top {n_features} Most Important Features - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not plot feature importance for {model_name}: {str(e)}\")\n",
    "\n",
    "def plot_learning_curves(estimator, title, X, y, ylim=None, cv=5,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"Plot learning curves for a given estimator\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_grid_search_results(grid_search, param_name):\n",
    "    \"\"\"Plot grid search results for a specific parameter\"\"\"\n",
    "    # Clear any existing plots\n",
    "    plt.clf()\n",
    "    \n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    \n",
    "    # Get the parameter values\n",
    "    param_values = [params[param_name] for params in results['params']]\n",
    "    \n",
    "    # Calculate mean scores for each parameter value\n",
    "    mean_scores = {}\n",
    "    std_scores = {}\n",
    "    for value, mean, std in zip(param_values, \n",
    "                               results['mean_test_score'],\n",
    "                               results['std_test_score']):\n",
    "        if value not in mean_scores:\n",
    "            mean_scores[value] = []\n",
    "            std_scores[value] = []\n",
    "        mean_scores[value].append(mean)\n",
    "        std_scores[value].append(std)\n",
    "    \n",
    "    # Calculate average for each parameter value\n",
    "    unique_values = sorted(set(param_values))\n",
    "    mean_scores = [np.mean(mean_scores[value]) for value in unique_values]\n",
    "    std_scores = [np.mean(std_scores[value]) for value in unique_values]\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.errorbar(range(len(unique_values)), mean_scores, \n",
    "                yerr=std_scores, fmt='o-')\n",
    "    \n",
    "    # Set the x-axis labels\n",
    "    plt.xticks(range(len(unique_values)), unique_values)\n",
    "    \n",
    "    # Labels and title\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('Mean CV Score')\n",
    "    plt.title(f'Grid Search Results for {param_name}')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, score in enumerate(mean_scores):\n",
    "        plt.text(i, score, f'{score:.3f}', \n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_param_results(grid_search, param_grid):\n",
    "    \"\"\"Plot grid search results for all parameters\"\"\"\n",
    "    n_params = len(param_grid)\n",
    "    if n_params == 0:\n",
    "        return\n",
    "        \n",
    "    # Calculate subplot layout\n",
    "    n_cols = min(3, n_params)\n",
    "    n_rows = (n_params + n_cols - 1) // n_cols\n",
    "    \n",
    "    plt.figure(figsize=(6*n_cols, 4*n_rows))\n",
    "    \n",
    "    for i, param_name in enumerate(param_grid.keys(), 1):\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        \n",
    "        results = pd.DataFrame(grid_search.cv_results_)\n",
    "        param_values = [params[param_name] for params in results['params']]\n",
    "        \n",
    "        # Custom sorting function that handles None\n",
    "        def sort_key(x):\n",
    "            if x is None:\n",
    "                return float('inf')  # Place None at the end\n",
    "            return x\n",
    "        \n",
    "        # Calculate mean scores for each parameter value\n",
    "        mean_scores = {}\n",
    "        std_scores = {}\n",
    "        for value, mean, std in zip(param_values, \n",
    "                                   results['mean_test_score'],\n",
    "                                   results['std_test_score']):\n",
    "            if value not in mean_scores:\n",
    "                mean_scores[value] = []\n",
    "                std_scores[value] = []\n",
    "            mean_scores[value].append(mean)\n",
    "            std_scores[value].append(std)\n",
    "        \n",
    "        # Sort values handling None\n",
    "        unique_values = sorted(set(param_values), key=sort_key)\n",
    "        mean_scores = [np.mean(mean_scores[value]) for value in unique_values]\n",
    "        std_scores = [np.mean(std_scores[value]) for value in unique_values]\n",
    "        \n",
    "        # Convert values to strings for display\n",
    "        x_labels = ['None' if v is None else str(v) for v in unique_values]\n",
    "        \n",
    "        # Plot\n",
    "        plt.errorbar(range(len(unique_values)), mean_scores, \n",
    "                    yerr=std_scores, fmt='o-')\n",
    "        plt.xticks(range(len(unique_values)), x_labels, rotation=45)\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel('Mean CV Score')\n",
    "        plt.title(f'Grid Search Results - {param_name}')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Add value labels\n",
    "        for j, score in enumerate(mean_scores):\n",
    "            plt.text(j, score, f'{score:.3f}', \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f655e1a-35d2-4698-ba23-ebe50de1703c",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0501ccf8-6015-4f71-becc-8773ba48c434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost version: 2.1.2\n",
      "GPU is working correctly\n"
     ]
    }
   ],
   "source": [
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "try:\n",
    "    # Try GPU-enabled classifier\n",
    "    clf = xgb.XGBClassifier(tree_method='gpu_hist')\n",
    "    print(\"GPU is working correctly\")\n",
    "except Exception as e:\n",
    "    print(f\"GPU test failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a57c15d-00f1-46e6-b427-ee30fae5565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_param_grids():\n",
    "    \"\"\"Define parameter grids for each model\"\"\"\n",
    "    param_grids = {\n",
    "        'XGBoost': {\n",
    "            'vectorizer__max_features': [2000, 3000, 4000, 1000, 12000, 15000],\n",
    "            'vectorizer__ngram_range': [(1,1), (1,2)],\n",
    "            'classifier__n_estimators': [50, 100, 200, 300, 400],\n",
    "            'classifier__max_depth': [3, 5, 7, 10],\n",
    "            'classifier__learning_rate': [0.04, 0.05, 0.07, 0.01, 0.02, 1.0, 2.0],\n",
    "            'classifier__tree_method': ['hist'],\n",
    "            'classifier__device': ['cuda']\n",
    "        },\n",
    "    }\n",
    "    return param_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b4f4def-6ac2-494f-b63a-835f54ffde86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transform data to match XGBoost's device\"\"\"\n",
    "    def __init__(self, device='cuda'):\n",
    "        self.device = device\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        # Handle sparse matrices\n",
    "        if scipy.sparse.issparse(X):\n",
    "            X = X.toarray()\n",
    "        \n",
    "        # Convert to torch tensor and move to appropriate device\n",
    "        X_tensor = torch.FloatTensor(X).to(self.device)\n",
    "        \n",
    "        # Always move to CPU before converting to numpy\n",
    "        return X_tensor.cpu().numpy()\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44bf64c1-9101-4a02-89b5-7dd79291c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_with_grid_search(X_train, X_test, y_train, y_test):\n",
    "    # Transform labels from 1-5 to 0-4\n",
    "    y_train_transformed = y_train - 1\n",
    "    y_test_transformed = y_test - 1\n",
    "\n",
    "    n_classes = len(np.unique(np.concatenate([y_train_transformed, y_test_transformed])))\n",
    "    \n",
    "    pipelines = {\n",
    "        'XGBoost': Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('to_dense', DeviceTransformer(device='cuda')),\n",
    "            ('classifier', XGBClassifier(\n",
    "                random_state=42,\n",
    "                objective='multi:softmax',\n",
    "                num_class=n_classes,\n",
    "                eval_metric='mlogloss',\n",
    "                enable_categorical=True,\n",
    "                tree_method='hist',\n",
    "                device='cuda'\n",
    "            ))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    param_grids = create_param_grids()\n",
    "    results = {}\n",
    "\n",
    "    for name, pipeline in pipelines.items():\n",
    "        print(f\"\\nTraining {name} with Grid Search...\")\n",
    "        \n",
    "        try:\n",
    "            # Print GPU info\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "                print(f\"Initial GPU Memory: {torch.cuda.memory_allocated()/1e6:.2f}MB\")\n",
    "\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Perform grid search\n",
    "            grid_search = GridSearchCV(\n",
    "                pipeline,\n",
    "                param_grids[name],\n",
    "                cv=5,\n",
    "                n_jobs=1,  # Use 1 for GPU\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train_transformed)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            print(f\"\\nTraining time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = grid_search.predict(X_test)\n",
    "            y_pred_original = y_pred + 1\n",
    "            y_test_original = y_test_transformed + 1\n",
    "\n",
    "            # Store results\n",
    "            results[name] = {\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'best_score': grid_search.best_score_,\n",
    "                'train_score': grid_search.score(X_train, y_train_transformed),\n",
    "                'test_score': grid_search.score(X_test, y_test_transformed),\n",
    "                'classification_report': classification_report(y_test_original, y_pred_original),\n",
    "                'confusion_matrix': confusion_matrix(y_test_original, y_pred_original),\n",
    "                'training_time': end_time - start_time\n",
    "            }\n",
    "\n",
    "            # Print results\n",
    "            print(f\"\\n{name} Results:\")\n",
    "            print(f\"Best parameters: {results[name]['best_params']}\")\n",
    "            print(f\"Best CV score: {results[name]['best_score']:.3f}\")\n",
    "            print(f\"Training accuracy: {results[name]['train_score']:.3f}\")\n",
    "            print(f\"Testing accuracy: {results[name]['test_score']:.3f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(results[name]['classification_report'])\n",
    "\n",
    "            # Plot confusion matrix\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            cm = results[name]['confusion_matrix']\n",
    "            cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "            sns.heatmap(cm_percentage, annot=True, fmt='.1f', cmap='Blues')\n",
    "            plt.title(f'{name} - Confusion Matrix (%)')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            plt.show()\n",
    "    \n",
    "            # Plot learning curves for best model\n",
    "            plot_learning_curves(\n",
    "                grid_search.best_estimator_,\n",
    "                f'Learning Curves - {name}',\n",
    "                X_train, y_train_transformed\n",
    "            )\n",
    "    \n",
    "            # Plot grid search results for all parameters\n",
    "            print(f\"\\nGrid Search Results for {name}:\")\n",
    "            plot_all_param_results(grid_search, param_grids[name])\n",
    "    \n",
    "            # Add this after other plots\n",
    "            print(f\"\\nTop Features for {name}:\")\n",
    "            plot_top_features(grid_search.best_estimator_, name)\n",
    "            print(f\"\\nClass-specific Features for {name}:\")\n",
    "            plot_top_features_by_class(grid_search.best_estimator_, name)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {str(e)}\")\n",
    "            raise  # This will show the full traceback\n",
    "            \n",
    "        finally:\n",
    "            # Clean up GPU memory\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                print(\"GPU memory cleared\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d5cc190-d1a2-4c73-a29f-df0529684417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost with Grid Search...\n",
      "Using GPU: NVIDIA GeForce GTX 1650 Ti\n",
      "Initial GPU Memory: 0.00MB\n",
      "Fitting 5 folds for each of 1680 candidates, totalling 8400 fits\n",
      "GPU memory cleared\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_models_with_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 47\u001b[0m, in \u001b[0;36mcompare_models_with_grid_search\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[1;32m     39\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     40\u001b[0m     pipeline,\n\u001b[1;32m     41\u001b[0m     param_grids[name],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/sklearn/pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/.virtualenv/AM1-TP/lib/python3.10/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = compare_models_with_grid_search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e41bdb-77c7-416d-9c4b-c15b2ebb73ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea2535a-df99-4401-a181-a063f7e548eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
